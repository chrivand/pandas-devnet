# Intro to the dataset and Pandas
In this lab you will lay a theoretical foundation about the dataset that you will use during this lab. You will also get some brief introduction to Pandas.

## Dataset

The dataset that you will use for the subsequent labs, is derived from a Cisco Secure Network Analytics flow search query export. Since Secure Network Analytics has a database with all transactions (flows) that happened in the network, you can do very precise search queries. This can be crucial during forensic research into cyber attacks. For the purpose of this lab, a flow search was done for without any filter parameters, apart from the chosen time windows (10 minutes). The goal of the subsequent labs is to use this unfiltered flow dataset and to calculate some baselines using Pandas. This will teach you how to use Pandas, but at the same time teaches you how the engine works. Please note, Cisco Secure Analytics uses a very complex combination of baseline, anomoly detection and other machine learning algorithms. This lab will be an extreme simplification of this for educational purposes. 

The exported dataset looks like below:

```
...,
{
      "Start": "2021-05-11T03:40:03.000+0000",
      "Duration": "7hr 57min 56s",
      "Subject IP Address": "10.201.3.20",
      "Subject Port/Protocol": "50928/TCP",
      "Subject Host Groups": "Web Servers, End User Devices, Desktops, Atlanta, Sales and Marketing",
      "Subject Bytes": "424.39 M",
      "Application": "Xsan Filesystem",
      "Total Bytes": "848.77 M",
      "Peer IP Address": "10.201.1.51",
      "Peer Port/Protocol": "22609/TCP",
      "Peer Host Groups": "Web Servers, Atlanta",
      "Peer Bytes": "424.39 M",
      "Actions": ""
},
...
```

Below are all of the keys explained in more detail:

* **Start**: start datetime of the flow. For example if you browse to a website, it will be the moment that your device set's op the HTTPS connection to a webserver on the internet.
* **Duration**: the duration of the flow.
* **Subject IP Address**: the IP address of the source or initiating device. For example a laptop.
* **Subject Port/Protocol**: the source port.
* **Subject Host Groups**: the group that defines what the device belongs to. These can be created by the admin and is used to calculate baselines with. 
* **Subject Bytes**: the amount of bytes that the source has sent.
* **Application**: the applications used (e.g HTTPS).
* **Total Bytes**: total amount of bytes sent and received.
* **Peer IP Address**: the IP address of the destination or receiving device. For example a webserver.
* **Peer Port/Protocol**: the destination port.
* **Peer Host Groups**: the group that defines what the device belongs to. These are also often hosts on the internet. They cannot always be defined by the admin.
* **Peer Bytes**: "424.39 M",

## Python Pandas

[Pandas](https://pandas.pydata.org/) is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,
built on top of the Python programming language. It is a very common and de-facto tool to use when working with datasets. 

Pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. It is free software released under the three-clause BSD license. The name is derived from the term "panel data", an econometrics term for data sets that include observations over multiple time periods for the same individuals. Its name is a play on the phrase "Python data analysis" itself. Wes McKinney started building what would become pandas at AQR Capital while he was a researcher there from 2007 to 2010.

### Features:

* DataFrame object for data manipulation with integrated indexing.
* Tools for reading and writing data between in-memory data structures and different file formats.
* Data alignment and integrated handling of missing data.
* Reshaping and pivoting of data sets.
* Label-based slicing, fancy indexing, and subsetting of large data sets.
* Data structure column insertion and deletion.
* Group by engine allowing split-apply-combine operations on data sets.
* Data set merging and joining.
* Hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data structure.
* Time series-functionality: Date range generation[6] and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging.
* Provides data filtration.
* The library is highly optimized for performance, with critical code paths written in Cython or C.

**Next Step: Hands-on excercise: import dataset with Python**